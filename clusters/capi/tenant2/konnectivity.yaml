---
apiVersion: v1
kind: Pod
metadata:
  name: konnectivity-server
  namespace: kube-system
spec:
  tolerations:
    - effect: NoSchedule
      key: node.cloudprovider.kubernetes.io/uninitialized
      value: 'true'
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
  priorityClassName: system-cluster-critical
  hostNetwork: true
  containers:
    - name: konnectivity-server-container
      image: registry.k8s.io/kas-network-proxy/proxy-server:v0.0.37
      command: [/proxy-server]
      args:
        - --logtostderr=true
            # This needs to be consistent with the value set in egressSelectorConfiguration.
        - --uds-name=/etc/kubernetes/konnectivity-server/konnectivity-server.socket
        - --delete-existing-uds-file
            # The following two lines assume the Konnectivity server is
            # deployed on the same machine as the apiserver, and the certs and
            # key of the API Server are at the specified location.
        - --cluster-cert=/etc/kubernetes/pki/apiserver.crt
        - --cluster-key=/etc/kubernetes/pki/apiserver.key
            # This needs to be consistent with the value set in egressSelectorConfiguration.
        - --mode=grpc
        - --server-port=0
        - --agent-port=8132
        - --admin-port=8133
        - --health-port=8134
        - --agent-namespace=kube-system
        - --agent-service-account=konnectivity-agent
        - --kubeconfig=/etc/kubernetes/admin.conf
        - --authentication-audience=system:konnectivity-server
      livenessProbe:
        httpGet:
          scheme: HTTP
          host: 127.0.0.1
          port: 8134
          path: /healthz
        initialDelaySeconds: 30
        timeoutSeconds: 60
      ports:
        - name: agentport
          containerPort: 8132
          hostPort: 8132
        - name: adminport
          containerPort: 8133
          hostPort: 8133
        - name: healthport
          containerPort: 8134
          hostPort: 8134
      volumeMounts:
        - name: k8s-certs
          mountPath: /etc/kubernetes/pki
          readOnly: true
        - name: kubeconfig
          mountPath: /etc/kubernetes/admin.conf
          readOnly: true
        - name: konnectivity-uds
          mountPath: /etc/kubernetes/konnectivity-server
          readOnly: false
  volumes:
    - name: k8s-certs
      hostPath:
        path: /etc/kubernetes/pki
    - name: kubeconfig
      hostPath:
        path: /etc/kubernetes/konnectivity-server.conf
        type: FileOrCreate
    - name: konnectivity-uds
      hostPath:
        path: /etc/kubernetes/konnectivity-server
        type: DirectoryOrCreate
---
apiVersion: apps/v1
# Alternatively, you can deploy the agents as Deployments. It is not necessary
# to have an agent on each node.
kind: DaemonSet
metadata:
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
    k8s-app: konnectivity-agent
  namespace: kube-system
  name: konnectivity-agent
spec:
  selector:
    matchLabels:
      k8s-app: konnectivity-agent
  template:
    metadata:
      labels:
        k8s-app: konnectivity-agent
    spec:
      priorityClassName: system-cluster-critical
      tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
      containers:
        - image: us.gcr.io/k8s-artifacts-prod/kas-network-proxy/proxy-agent:v0.0.37
          name: konnectivity-agent
          command: [/proxy-agent]
          args:
            - --logtostderr=true
            - --ca-cert=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                  # Since the konnectivity server runs with hostNetwork=true,
                  # this is the IP address of the master machine.
            - --proxy-server-host=87.228.76.100
            - --proxy-server-port=8132
            - --admin-server-port=8133
            - --health-server-port=8134
            - --service-account-token-path=/var/run/secrets/tokens/konnectivity-agent-token
          volumeMounts:
            - mountPath: /var/run/secrets/tokens
              name: konnectivity-agent-token
          livenessProbe:
            httpGet:
              port: 8134
              path: /healthz
            initialDelaySeconds: 15
            timeoutSeconds: 15
      serviceAccountName: konnectivity-agent
      volumes:
        - name: konnectivity-agent-token
          projected:
            sources:
              - serviceAccountToken:
                  path: konnectivity-agent-token
                  audience: system:konnectivity-server
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: system:konnectivity-server
  labels:
    kubernetes.io/cluster-service: 'true'
    addonmanager.kubernetes.io/mode: Reconcile
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
  - apiGroup: rbac.authorization.k8s.io
    kind: User
    name: system:konnectivity-server
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: konnectivity-agent
  namespace: kube-system
  labels:
    kubernetes.io/cluster-service: 'true'
    addonmanager.kubernetes.io/mode: Reconcile
